{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTEqqZMIiom-"
   },
   "source": [
    "#### Download data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XSU2sC0zj_q"
   },
   "source": [
    "1.   We will download the zip for the data in the repo\n",
    "2.   The database dataset contains the signatures of **260 persons**.\n",
    "3.   Out of 260, 100 were signed in **Bengali** and 160 are signed in **Hindi**.\n",
    "4.   For each signers, there are **24 genuine** and **30 forged** signatures available. \n",
    "5.   In Bengali, we have 2400 (100 x 24) genuine and 3000 (100 x 30) forged signatures.\n",
    "6.   In Hindi, we have 3840 (160 x 24) genuine 4800 (160 x 30) forged signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWu5sCKTn-wq"
   },
   "outputs": [],
   "source": [
    "#Install package\n",
    "!pip install googledrivedownloader --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLOYv28B0ZMm"
   },
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "go2w2yTW1XRR",
    "outputId": "e753a7b4-50b9-4e05-edea-75985c05e48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0B29vNACcjvzVc1RfVkg5dUh2b1E into ./BHSig260.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "#Download file\n",
    "gdd.download_file_from_google_drive(file_id='0B29vNACcjvzVc1RfVkg5dUh2b1E', #file id as per link\n",
    "                                    dest_path='./BHSig260.zip', #File name given to downloaded file\n",
    "                                    unzip=True) #Unzip the downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "SvSAyKMj0o_t",
    "outputId": "291f84a0-e641-4c0e-f371-89b5939d14a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 47376\n",
      "drwxr-xr-x 4 root root     4096 Jul 18 13:23 BHSig260\n",
      "-rw-r--r-- 1 root root 48500114 Jul 18 13:23 BHSig260.zip\n",
      "drwxr-xr-x 1 root root     4096 Jul 10 16:29 sample_data\n"
     ]
    }
   ],
   "source": [
    "#Check if the file exists\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "q9WuX2d-864V",
    "outputId": "7a25a565-c012-4c9c-b3b8-86ea63e2f804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 102 root root 4096 Jul 18 13:24 Bengali\n",
      "drwxr-xr-x 162 root root 4096 Jul 18 13:24 Hindi\n"
     ]
    }
   ],
   "source": [
    "#Check dataset folder\n",
    "!ls -l BHSig260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QEjneSevCThU",
    "outputId": "2f52cf20-088a-4c65-c825-54f20462beac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1168\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 001\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 002\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 003\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 004\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 005\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 006\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 007\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 008\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 009\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 010\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 011\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 012\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 013\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 014\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 015\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 016\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 017\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 018\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 019\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 020\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 021\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 022\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 023\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 024\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 025\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 026\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 027\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 028\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 029\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 030\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 031\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 032\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 033\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 034\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 035\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 036\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 037\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 038\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 039\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 040\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 041\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 042\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 043\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 044\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 045\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 046\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 047\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 048\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 049\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 050\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 051\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 052\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 053\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 054\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 055\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 056\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 057\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 058\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 059\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 060\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 061\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 062\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 063\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 064\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 065\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 066\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 067\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 068\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 069\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 070\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 071\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 072\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 073\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 074\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 075\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 076\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 077\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 078\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 079\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 080\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 081\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 082\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 083\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 084\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 085\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 086\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 087\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 088\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 089\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 090\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 091\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 092\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 093\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:24 094\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 095\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 096\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 097\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 098\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 099\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 100\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 101\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 102\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 103\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 104\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 105\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 106\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 107\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 108\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 109\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 110\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 111\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 112\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 113\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 114\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 115\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 116\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 117\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 118\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 119\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 120\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 121\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 122\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 123\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 124\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 125\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 126\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 127\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 128\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 129\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 130\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 131\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 132\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 133\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 134\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 135\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 136\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 137\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 138\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 139\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 140\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 141\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 142\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 143\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 144\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 145\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 146\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 147\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 148\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 149\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 150\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 151\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 152\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 153\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 154\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 155\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 156\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 157\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 158\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 159\n",
      "drwxr-xr-x 2 root root   4096 Jul 18 13:23 160\n",
      "-rw-r--r-- 1 root root 358560 Jul 18 13:23 Hindi_pairs.txt\n",
      "-rw-r--r-- 1 root root  97770 Jul 18 13:23 list.forgery\n",
      "-rw-r--r-- 1 root root  78216 Jul 18 13:23 list.genuine\n"
     ]
    }
   ],
   "source": [
    "!ls -l BHSig260/Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 968
    },
    "id": "stdqGXfq8_Go",
    "outputId": "e73328dd-941d-46eb-9307-b60b32e57ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14932\n",
      "-rw-r--r-- 1 root root 278048 Jul 18 13:23 H-S-1-F-01.tif\n",
      "-rw-r--r-- 1 root root 278048 Jul 18 13:23 H-S-1-F-02.tif\n",
      "-rw-r--r-- 1 root root 290756 Jul 18 13:23 H-S-1-F-03.tif\n",
      "-rw-r--r-- 1 root root 276374 Jul 18 13:23 H-S-1-F-04.tif\n",
      "-rw-r--r-- 1 root root 277570 Jul 18 13:23 H-S-1-F-05.tif\n",
      "-rw-r--r-- 1 root root 288976 Jul 18 13:23 H-S-1-F-06.tif\n",
      "-rw-r--r-- 1 root root 274136 Jul 18 13:23 H-S-1-F-07.tif\n",
      "-rw-r--r-- 1 root root 274136 Jul 18 13:23 H-S-1-F-08.tif\n",
      "-rw-r--r-- 1 root root 294131 Jul 18 13:23 H-S-1-F-09.tif\n",
      "-rw-r--r-- 1 root root 279026 Jul 18 13:23 H-S-1-F-10.tif\n",
      "-rw-r--r-- 1 root root 279026 Jul 18 13:23 H-S-1-F-11.tif\n",
      "-rw-r--r-- 1 root root 293100 Jul 18 13:23 H-S-1-F-12.tif\n",
      "-rw-r--r-- 1 root root 278048 Jul 18 13:23 H-S-1-F-13.tif\n",
      "-rw-r--r-- 1 root root 278332 Jul 18 13:23 H-S-1-F-14.tif\n",
      "-rw-r--r-- 1 root root 290288 Jul 18 13:23 H-S-1-F-15.tif\n",
      "-rw-r--r-- 1 root root 275395 Jul 18 13:23 H-S-1-F-16.tif\n",
      "-rw-r--r-- 1 root root 275114 Jul 18 13:23 H-S-1-F-17.tif\n",
      "-rw-r--r-- 1 root root 294131 Jul 18 13:23 H-S-1-F-18.tif\n",
      "-rw-r--r-- 1 root root 279026 Jul 18 13:23 H-S-1-F-19.tif\n",
      "-rw-r--r-- 1 root root 279026 Jul 18 13:23 H-S-1-F-20.tif\n",
      "-rw-r--r-- 1 root root 292069 Jul 18 13:23 H-S-1-F-21.tif\n",
      "-rw-r--r-- 1 root root 277070 Jul 18 13:23 H-S-1-F-22.tif\n",
      "-rw-r--r-- 1 root root 277070 Jul 18 13:23 H-S-1-F-23.tif\n",
      "-rw-r--r-- 1 root root 288696 Jul 18 13:23 H-S-1-F-24.tif\n",
      "-rw-r--r-- 1 root root 274416 Jul 18 13:23 H-S-1-F-25.tif\n",
      "-rw-r--r-- 1 root root 274136 Jul 18 13:23 H-S-1-F-26.tif\n",
      "-rw-r--r-- 1 root root 278048 Jul 18 13:23 H-S-1-F-27.tif\n",
      "-rw-r--r-- 1 root root 278048 Jul 18 13:23 H-S-1-F-28.tif\n",
      "-rw-r--r-- 1 root root 288696 Jul 18 13:23 H-S-1-F-29.tif\n",
      "-rw-r--r-- 1 root root 293100 Jul 18 13:23 H-S-1-F-30.tif\n",
      "-rw-r--r-- 1 root root 276787 Jul 18 13:23 H-S-1-G-01.tif\n",
      "-rw-r--r-- 1 root root 277353 Jul 18 13:23 H-S-1-G-02.tif\n",
      "-rw-r--r-- 1 root root 290937 Jul 18 13:23 H-S-1-G-03.tif\n",
      "-rw-r--r-- 1 root root 276787 Jul 18 13:23 H-S-1-G-04.tif\n",
      "-rw-r--r-- 1 root root 277353 Jul 18 13:23 H-S-1-G-05.tif\n",
      "-rw-r--r-- 1 root root 275810 Jul 18 13:23 H-S-1-G-06.tif\n",
      "-rw-r--r-- 1 root root 276374 Jul 18 13:23 H-S-1-G-07.tif\n",
      "-rw-r--r-- 1 root root 290937 Jul 18 13:23 H-S-1-G-08.tif\n",
      "-rw-r--r-- 1 root root 276787 Jul 18 13:23 H-S-1-G-09.tif\n",
      "-rw-r--r-- 1 root root 277353 Jul 18 13:23 H-S-1-G-10.tif\n",
      "-rw-r--r-- 1 root root 289910 Jul 18 13:23 H-S-1-G-11.tif\n",
      "-rw-r--r-- 1 root root 275810 Jul 18 13:23 H-S-1-G-12.tif\n",
      "-rw-r--r-- 1 root root 276656 Jul 18 13:23 H-S-1-G-13.tif\n",
      "-rw-r--r-- 1 root root 291964 Jul 18 13:23 H-S-1-G-14.tif\n",
      "-rw-r--r-- 1 root root 277764 Jul 18 13:23 H-S-1-G-15.tif\n",
      "-rw-r--r-- 1 root root 278332 Jul 18 13:23 H-S-1-G-16.tif\n",
      "-rw-r--r-- 1 root root 290654 Jul 18 13:23 H-S-1-G-17.tif\n",
      "-rw-r--r-- 1 root root 277070 Jul 18 13:23 H-S-1-G-18.tif\n",
      "-rw-r--r-- 1 root root 277353 Jul 18 13:23 H-S-1-G-19.tif\n",
      "-rw-r--r-- 1 root root 290937 Jul 18 13:23 H-S-1-G-20.tif\n",
      "-rw-r--r-- 1 root root 276787 Jul 18 13:23 H-S-1-G-21.tif\n",
      "-rw-r--r-- 1 root root 277636 Jul 18 13:23 H-S-1-G-22.tif\n",
      "-rw-r--r-- 1 root root 275810 Jul 18 13:23 H-S-1-G-23.tif\n",
      "-rw-r--r-- 1 root root 290937 Jul 18 13:23 H-S-1-G-24.tif\n"
     ]
    }
   ],
   "source": [
    "#Check data in Hindi folder\n",
    "!ls -l BHSig260/Hindi/001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8wh90Ho6T2x"
   },
   "source": [
    "#### Data preparation\n",
    "\n",
    "We will use only Hindi signatures for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxB-WZlg6fZO"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smlHEXb86oeU"
   },
   "source": [
    "Get list of signature directories (1 directory per person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7gAhIAW6nFI"
   },
   "outputs": [],
   "source": [
    "#Path to Hindi signatures\n",
    "path = 'BHSig260/Hindi/'\n",
    "\n",
    "#Get the list of all directories and sort them\n",
    "dir_list = next(os.walk(path))[1]\n",
    "dir_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "b4IPVn_n7VcY",
    "outputId": "83c4d06f-d9d0-47ba-8052-736fe88a14b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160']\n"
     ]
    }
   ],
   "source": [
    "#List of directories\n",
    "print(dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S18S_uQ77kuC"
   },
   "source": [
    "Get signature filenames for each person (1 Directory).\n",
    "- For each person, first 30 pictures are forged signature\n",
    "- Last 24 pictures in the directory are genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oCeEk0w74Of"
   },
   "outputs": [],
   "source": [
    "#Start with empty list of original and fake signatures\n",
    "genuine_signs = []\n",
    "forged_signs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTzncjjA8GrY"
   },
   "outputs": [],
   "source": [
    "#Loop through each directory\n",
    "for directory in dir_list:\n",
    "\n",
    "    #Read all image file names in the directory\n",
    "    images = os.listdir(path+directory)\n",
    "    images.sort()\n",
    "\n",
    "    #Add path to image name\n",
    "    images = [path+directory + '/'+ x for x in images]\n",
    "\n",
    "    #First 30 signs are forged\n",
    "    forged_signs.append(images[:30])\n",
    "    #Last 24 signs are genuine\n",
    "    genuine_signs.append(images[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "oXUGc3j48xpD",
    "outputId": "9dbf837d-a218-48da-91d8-5cbd8edf3d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with genuine signs: 160\n",
      "Number of people with forged signs: 160\n"
     ]
    }
   ],
   "source": [
    "#Check if we have 160 people's genuine and forged signatures\n",
    "print('Number of people with genuine signs:', len(genuine_signs))\n",
    "print('Number of people with forged signs:', len(forged_signs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rbLrF7UIDGFI",
    "outputId": "57583c55-69d0-44bf-ff74-f767a4906cb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genuine_signs[10]), len(forged_signs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoVk7yzc9V7Z"
   },
   "source": [
    "Split between Training and Test. We will use first 80% directories for training and last 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bbIKdWz9iLf"
   },
   "outputs": [],
   "source": [
    "train_g, test_g = genuine_signs[:128], genuine_signs[128:]\n",
    "train_f, test_f = forged_signs[:128], forged_signs[128:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ7CheTq979y"
   },
   "source": [
    "#### Visualize Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt-sQ4O1_bJw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSxGYc3ZnWE5"
   },
   "outputs": [],
   "source": [
    "def visualize_signatures():\n",
    "\n",
    "    \"\"\"\n",
    "    1. Randomly select a person id\n",
    "    2. Show two genuine signatures for the person\n",
    "    3. Show one forged signature for the same person\n",
    "    \"\"\"\n",
    "    \n",
    "    #Pick up a person from 160 people\n",
    "    person_id = np.random.randint(0, len(genuine_signs))\n",
    "\n",
    "    #Read genuine signature pics\n",
    "    genuine1, genuine2 = np.random.randint(0, 24, 2) #Get two pics randomly\n",
    "    original_img = tf.keras.preprocessing.image.load_img(genuine_signs[person_id][genuine1])#, color_mode='grayscale')\n",
    "    genuine_img = tf.keras.preprocessing.image.load_img(genuine_signs[person_id][genuine2])#, color_mode='grayscale')\n",
    "\n",
    "    #Read forged signature of same person\n",
    "    forged1 = np.random.randint(0, 30)\n",
    "    forged_img = tf.keras.preprocessing.image.load_img(forged_signs[person_id][forged1])#, color_mode='grayscale')\n",
    "\n",
    "    #Display pictures    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 10))\n",
    "\n",
    "    ax1.set_title('Genuine sign')\n",
    "    ax1.imshow(original_img, cmap = 'gray')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.set_title('Genuine sign')\n",
    "    ax2.imshow(genuine_img, cmap = 'gray')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.set_title('Forged sign')\n",
    "    ax3.imshow(forged_img, cmap = 'gray')\n",
    "    ax3.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "ODvJ52T3-AMu",
    "outputId": "fa1761d1-ae5a-4dd9-de3d-dc092079b7e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_signatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YAIYkwwB-5Z"
   },
   "source": [
    "#### Building signature pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmWAXweiCeRI"
   },
   "source": [
    "Siamese network requires **two inputs** (rather than one we use with other models). In this case, the two input could be a \n",
    "1. Combination of **genuine-genuine** signatures\n",
    "2. Combination of **genuine-forged** signatures\n",
    "\n",
    "In the dataset, for each person, we have 24 genuine signatures and 30 forged signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMLXIdNODe0U"
   },
   "source": [
    "How many pairs can we create for model training. For each person...\n",
    "\n",
    "1. We can have 24 C 2 i.e 276 **genuine-genuine** pairs\n",
    "2. We can have 24 x 30 = 720 **genuine-forged** pairs\n",
    "\n",
    "This will make distribution to be 276:720 *i.e* 1:3 (approximate). \n",
    "\n",
    "To make the distribution even between different type of pairs, we will randomly take only 12 forged pictures (out of 30). This will make us have 24 x 12 = **288** genuine-forged pairs for each person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LG06fc0SFE6G"
   },
   "source": [
    "**Question: How many pairs we will have in training and test dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xFThzdqGSRZ"
   },
   "source": [
    "Build genuine-genuine pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Cgp5DiTGUWd"
   },
   "outputs": [],
   "source": [
    "def build_genuine_pairs(sig_list):\n",
    "\n",
    "    pairs_list = []\n",
    "\n",
    "    for person_id in range(len(sig_list)):\n",
    "\n",
    "        for i in range(len(sig_list[0])-1):\n",
    "            for j in range(i+1, len(sig_list[0])):\n",
    "\n",
    "                pairs_list.append([sig_list[person_id][i], sig_list[person_id][j]])\n",
    "    \n",
    "    return pairs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EZaAnpNHaWo"
   },
   "outputs": [],
   "source": [
    "#Build training and test pairs\n",
    "train_g_g_pairs = build_genuine_pairs(train_g)\n",
    "test_g_g_pairs = build_genuine_pairs(test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "fnYj19wtHogp",
    "outputId": "8a19844f-7e09-4f8a-8ae6-a2b7d7e4b85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genuine pairs in training set: 35328\n",
      "Number of genuine pairs in test set: 8832\n"
     ]
    }
   ],
   "source": [
    "#Check number of pairs in training and test\n",
    "print('Number of genuine pairs in training set:', len(train_g_g_pairs))\n",
    "print('Number of genuine pairs in test set:', len(test_g_g_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXAvUc6zID7m"
   },
   "source": [
    "Build genuine-fake pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-s1Yr8nIGMA"
   },
   "outputs": [],
   "source": [
    "def build_gen_forged_pairs(gen_sigs, forged_sigs):\n",
    "\n",
    "    pairs_list = []\n",
    "\n",
    "    for person_id in range(len(gen_sigs)):\n",
    "\n",
    "        #Let's pickup 12 random numbers for forged signatures\n",
    "        forged_ids = np.random.randint(0, len(forged_sigs[0]), 12)\n",
    "\n",
    "        for i in range(len(gen_sigs[0])):\n",
    "            for j in forged_ids:\n",
    "                pairs_list.append([gen_sigs[person_id][i], forged_sigs[person_id][j]])\n",
    "    \n",
    "    return pairs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FdgxIqjJYof"
   },
   "outputs": [],
   "source": [
    "#Build training and test pairs\n",
    "train_g_f_pairs = build_gen_forged_pairs(train_g, train_f)\n",
    "test_g_f_pairs = build_gen_forged_pairs(test_g, test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ZaagN-Z1J_o8",
    "outputId": "bd4e0169-f96c-4010-e35b-6b15fab00c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genuine-forged pairs in training set: 36864\n",
      "Number of genuine-forged pairs in test set: 9216\n"
     ]
    }
   ],
   "source": [
    "#Check number of pairs in training and test\n",
    "print('Number of genuine-forged pairs in training set:', len(train_g_f_pairs))\n",
    "print('Number of genuine-forged pairs in test set:', len(test_g_f_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "A1_7oZGPeg-L",
    "outputId": "90e64505-faa2-40a0-e76e-40e017b3f920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72192"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of examples in training\n",
    "len(train_g_g_pairs) +  len(train_g_f_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWT_Wb_OLaBk"
   },
   "source": [
    "#### Build Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nE5HMf3XZLzw"
   },
   "outputs": [],
   "source": [
    "#Set image Size\n",
    "img_width = 330\n",
    "img_height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ac1ky-FLcV0"
   },
   "outputs": [],
   "source": [
    "def batch_generator(gen_gen_list, gen_forged_list, batch_size=32):\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        first_img_array = np.zeros((batch_size, img_height, img_width, 3))\n",
    "        second_img_array = np.zeros((batch_size, img_height, img_width, 3))\n",
    "        batch_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        #Generate batch_size ids for both type of pairs\n",
    "        gen_gen_pair_idx = np.random.randint(0, len(gen_gen_list), batch_size//2)\n",
    "        gen_forged_pair_idx = np.random.randint(0, len(gen_forged_list), batch_size//2)\n",
    "\n",
    "        for i in range(batch_size//2):\n",
    "\n",
    "            #Get images from gen_gen pair\n",
    "            gg_id = gen_gen_pair_idx[i]\n",
    "            first_img = tf.keras.preprocessing.image.load_img(gen_gen_list[gg_id][0], target_size=(img_height, img_width))\n",
    "            second_img = tf.keras.preprocessing.image.load_img(gen_gen_list[gg_id][1], target_size=(img_height, img_width))\n",
    "            \n",
    "            first_img_array[2*i] = tf.keras.preprocessing.image.img_to_array(first_img)\n",
    "            second_img_array[2*i] = tf.keras.preprocessing.image.img_to_array(second_img)\n",
    "\n",
    "            #Genuine genuine pair will be a given a label of '1'\n",
    "            batch_labels[2*i] = 1\n",
    "\n",
    "            #Get images from gen_forged pair\n",
    "            gf_id = gen_forged_pair_idx[i]\n",
    "            first_img = tf.keras.preprocessing.image.load_img(gen_forged_list[gf_id][0], target_size=(img_height, img_width))\n",
    "            second_img = tf.keras.preprocessing.image.load_img(gen_forged_list[gf_id][1], target_size=(img_height, img_width))\n",
    "            \n",
    "            first_img_array[2*i+1] = tf.keras.preprocessing.image.img_to_array(first_img)\n",
    "            second_img_array[2*i+1] = tf.keras.preprocessing.image.img_to_array(second_img)\n",
    "\n",
    "            #Genuine genuine-forged pair will be a given a label of '0'\n",
    "            batch_labels[2*i+1] = 0\n",
    "        \n",
    "        #Normalize data\n",
    "        first_img_array = tf.keras.applications.mobilenet.preprocess_input(first_img_array)\n",
    "        second_img_array = tf.keras.applications.mobilenet.preprocess_input(second_img_array)\n",
    "\n",
    "        yield [first_img_array, second_img_array], batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkMXRqyZfSto"
   },
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pix5JrrrgKgF"
   },
   "source": [
    "Load a pre-trained model (we can build a model from scratch as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "vql7Dga6fT_7",
    "outputId": "7b84c553-2fb6-4567-f30a-84663492b83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_5_0_224_tf_no_top.h5\n",
      "5578752/5577668 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(include_top=False, \n",
    "                                                      input_shape=(img_height, img_width,3),\n",
    "                                                      alpha=0.5,\n",
    "                                                      weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jN94jN-5fuCz",
    "outputId": "caccaea6-daf1-4b6b-f3b7-f95473827a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_0.50_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 330, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 101, 331, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 50, 165, 16)       432       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 50, 165, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 50, 165, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 50, 165, 16)       144       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 50, 165, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 50, 165, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 50, 165, 32)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 50, 165, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 50, 165, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 51, 166, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 25, 82, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 25, 82, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 25, 82, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 25, 82, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 25, 82, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 25, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 25, 82, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 25, 82, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 25, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 25, 82, 64)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 25, 82, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 25, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 26, 83, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 12, 41, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 12, 41, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 12, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 12, 41, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 12, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 12, 41, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 12, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 12, 41, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 12, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 13, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 6, 20, 128)        1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 6, 20, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 6, 20, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 6, 20, 256)        32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 7, 21, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 3, 10, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 3, 10, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 3, 10, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 3, 10, 512)        131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 3, 10, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 3, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 3, 10, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 3, 10, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 3, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 3, 10, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 3, 10, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 3, 10, 512)        0         \n",
      "=================================================================\n",
      "Total params: 829,536\n",
      "Trainable params: 818,592\n",
      "Non-trainable params: 10,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "63HBcG2vuGJZ",
    "outputId": "0f0b486e-e264-46f3-aa85-8769c7f709b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of layers in Mobilenet\n",
    "len(mobilenet.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_1PqDcruNGp"
   },
   "outputs": [],
   "source": [
    "#Lets' freeze all but last 15 layers\n",
    "for layer in mobilenet.layers[:72]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J4wu1qFyukWR",
    "outputId": "8bbb87b3-ea2f-44ab-ac6a-fe1b42082bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_0.50_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 330, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 101, 331, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 50, 165, 16)       432       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 50, 165, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 50, 165, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 50, 165, 16)       144       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 50, 165, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 50, 165, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 50, 165, 32)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 50, 165, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 50, 165, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 51, 166, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 25, 82, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 25, 82, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 25, 82, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 25, 82, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 25, 82, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 25, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 25, 82, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 25, 82, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 25, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 25, 82, 64)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 25, 82, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 25, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 26, 83, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 12, 41, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 12, 41, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 12, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 12, 41, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 12, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 12, 41, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 12, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 12, 41, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 12, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 13, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 6, 20, 128)        1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 6, 20, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 6, 20, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 6, 20, 256)        32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 6, 20, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 6, 20, 256)        65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 6, 20, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 6, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 7, 21, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 3, 10, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 3, 10, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 3, 10, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 3, 10, 512)        131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 3, 10, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 3, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 3, 10, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 3, 10, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 3, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 3, 10, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 3, 10, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 3, 10, 512)        0         \n",
      "=================================================================\n",
      "Total params: 829,536\n",
      "Trainable params: 404,224\n",
      "Non-trainable params: 425,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSccHAlwgVB4"
   },
   "source": [
    "Build a Siamese Network using Mobilenet as feature generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP7OWcFTgbl1"
   },
   "outputs": [],
   "source": [
    "#Create two input layers - first and second image\n",
    "first_input = tf.keras.layers.Input(shape=(img_height, img_width,3))\n",
    "second_input = tf.keras.layers.Input(shape=(img_height, img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qexPPs_Ugrrd"
   },
   "outputs": [],
   "source": [
    "#Generate features for first and second image\n",
    "first_img_features = mobilenet(first_input)\n",
    "second_img_features = mobilenet(second_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "e952as6rgr4A",
    "outputId": "ada9a1d1-d389-40bc-999d-04b9c7ef5a31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mobilenet_0.50_224/Identity:0' shape=(None, 3, 10, 512) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of the outputs\n",
    "first_img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_gjhK_Qjqmc"
   },
   "outputs": [],
   "source": [
    "#Lets flatten the features using Average pooling\n",
    "gap_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "#First img features\n",
    "first_img_features = gap_layer(first_img_features)\n",
    "#Second image features\n",
    "second_img_features = gap_layer(second_img_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFIcFINMkLu-"
   },
   "source": [
    "We want to calculate Euclidean distance between two feature set. As there is no pre-built Euclidean distance layer in Keras, we will build one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8yA71drkGvK"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(features):\n",
    "    \n",
    "    #Get features\n",
    "    x, y = features\n",
    "\n",
    "    #Calculate distance\n",
    "    distance = tf.keras.backend.sqrt(tf.keras.backend.sum(tf.keras.backend.square(x - y), axis=1, keepdims=True))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Poz-43lWk-3R"
   },
   "source": [
    "We will also need a function to define output shape of Euclidean distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG1XWOH5k40X"
   },
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "\n",
    "    #Shapes of feature 1 and 2\n",
    "    shape1, shape2 = shapes\n",
    "    \n",
    "    #Returned shape is equal to number of examples, 1\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rn5HLsZ-lHP7"
   },
   "source": [
    "Use Eucledean distance layer on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIOuH3m5lMrM"
   },
   "outputs": [],
   "source": [
    "distance = tf.keras.layers.Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([first_img_features, second_img_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT6-P307l5Dc"
   },
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-779UAgl3-N"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model([first_input, second_input], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "mL1CvCg3ith_",
    "outputId": "cb161340-4c52-49f9-a35c-2867be5fd14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 330, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 100, 330, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenet_0.50_224 (Model)      (None, 3, 10, 512)   829536      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           mobilenet_0.50_224[1][0]         \n",
      "                                                                 mobilenet_0.50_224[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_average_pooling2d[1][0]   \n",
      "==================================================================================================\n",
      "Total params: 829,536\n",
      "Trainable params: 404,224\n",
      "Non-trainable params: 425,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GQD86eEmHkm"
   },
   "source": [
    "How do we calculate loss for Siamese network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZogiZ3UnWFf"
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    y_pred : Eucledean distance for each pair of images\n",
    "    y_true : 1 for Genuine-genuine pair, 0 otherwise\n",
    "    \n",
    "    Contrastive loss from Hadsell-et-al.'06\n",
    "    Source: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \n",
    "    Explanation:\n",
    "    When ytrue is 1, that means the sample are duplicates of each other, \n",
    "    so the Euclidean distance (ypred) between their outputs must be minimized.\n",
    "    So the loss is taken as the square of that Euclidean distance itself - square(y_pred).\n",
    "\n",
    "    When ytrue is 0, i.e. the samples are not duplicates, then the Euclidean distance \n",
    "    between them must be maximized, at least to the margin. So the loss to be minimized\n",
    "    is the difference of the margin and the Euclidean distance - (margin - y_pred).\n",
    "    If the Euclidean distance (ypred) is already greater than the margin, \n",
    "    then nothing is to be learned, so the loss is made to be zero in \n",
    "    that case by saying maximum(margin - y_pred, 0).\n",
    "    \"\"\"\n",
    "\n",
    "    margin = 1\n",
    "\n",
    "    #Loss when pairs are genuine-genuine\n",
    "    positive_loss = tf.keras.backend.square(y_pred)\n",
    "    \n",
    "    #Loss when pairs are genuine-fake\n",
    "    negative_loss = tf.keras.backend.square(tf.keras.backend.maximum(margin - y_pred, 0))\n",
    "\n",
    "    #Total loss\n",
    "    total_loss = y_true * positive_loss + (1 - y_true) * negative_loss\n",
    "    \n",
    "    #Calculate average loss\n",
    "    total_average_loss = tf.keras.backend.mean(total_loss)\n",
    "\n",
    "    return total_average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoXmEpF2nlgS"
   },
   "source": [
    "Compile the model with optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXA8T8ONnnzv"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "w9BEs2VpnyEX",
    "outputId": "f7d6dee3-3a99-4710-d82a-68758e6a832a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 330, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 100, 330, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenet_0.50_224 (Model)      (None, 3, 10, 512)   829536      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           mobilenet_0.50_224[1][0]         \n",
      "                                                                 mobilenet_0.50_224[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_average_pooling2d[1][0]   \n",
      "==================================================================================================\n",
      "Total params: 829,536\n",
      "Trainable params: 404,224\n",
      "Non-trainable params: 425,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zctr-X7Sn2wv"
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkA103s-oMSh"
   },
   "outputs": [],
   "source": [
    "#Total training and test examples\n",
    "total_train_examples = len(train_g_g_pairs) + len(train_g_f_pairs)\n",
    "total_test_examples = len(test_g_g_pairs) + len(test_g_f_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "nNnPEhlpOqAR",
    "outputId": "6f00d4a3-c96d-46de-ec0b-cc6bdbb8b29b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72192, 18048)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_examples, total_test_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnLvtqe9n1Bv"
   },
   "outputs": [],
   "source": [
    "#Create Train and Test batch generators\n",
    "batch_size = 128\n",
    "train_generator = batch_generator(train_g_g_pairs, train_g_f_pairs, batch_size=batch_size)\n",
    "test_generator = batch_generator(test_g_g_pairs, test_g_f_pairs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxwqkUi8pG_f"
   },
   "outputs": [],
   "source": [
    "#Model checkpoint to save the best model\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint('signature_siamese.h5', \n",
    "                                                save_best_only=True, \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrV-3h8FoZ_k"
   },
   "outputs": [],
   "source": [
    "#Start training\n",
    "model.fit(train_generator,\n",
    "          epochs=1,\n",
    "          steps_per_epoch=total_train_examples//batch_size, \n",
    "          validation_data=test_generator, \n",
    "          validation_steps=total_test_examples//batch_size, \n",
    "          callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xXYjsMUAy7y"
   },
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsJ5o5gvAfzL"
   },
   "outputs": [],
   "source": [
    "#Connect to Google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bm4dSAOs_8iS"
   },
   "outputs": [],
   "source": [
    "#Save model - change path to whatever you want\n",
    "save_path = '<save_path>'\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keMTaG-lA3M0"
   },
   "outputs": [],
   "source": [
    "#Load model\n",
    "model = tf.keras.models.load_model(save_path, custom_objects={'contrastive_loss':contrastive_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxsbC7iJBwEJ"
   },
   "outputs": [],
   "source": [
    "#Make sure model has loaded\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X28jYq8NqkmF"
   },
   "source": [
    "#### Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTlVj7zp7o02"
   },
   "source": [
    "Calculate prediction for all test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYh7abc2vcuD"
   },
   "outputs": [],
   "source": [
    "#Build predictions\n",
    "predictions = []\n",
    "true_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ho03lUb8q5S"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(total_test_examples//batch_size)):\n",
    "\n",
    "    #Get batch\n",
    "    X, y = next(test_generator)\n",
    "    #Model predictions\n",
    "    distances = model.predict(X)\n",
    "\n",
    "    #Capture it in the labels and predictions list\n",
    "    for j in range(y.shape[0]):\n",
    "        true_labels.append(int(y[j][0]))\n",
    "        predictions.append(distances[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaSN7S47-K0B"
   },
   "outputs": [],
   "source": [
    "len(predictions), len(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPH3Dx2NqnpV"
   },
   "source": [
    "How do we calculate a **threhold** above which images will be considered as genuine-forged pair?\n",
    "\n",
    "*We can check at which distance, test accuracy is highest and consider that as a threhold.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZPIyYydqnCO"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy_thresh(predictions, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute accuracy with a range of thresholds on distances.\n",
    "    \"\"\"\n",
    "\n",
    "    #Get maximum and minimum value of distance for test examples\n",
    "    dmax = np.max(predictions)\n",
    "    dmin = np.min(predictions)\n",
    "\n",
    "    #How many pairs are genuine-genuine and how many are genuine-forged in test data\n",
    "    n_gg_pairs = np.sum(labels == 1)\n",
    "    n_gf_pairs = np.sum(labels == 0)\n",
    "    \n",
    "    #We will increment threhold by\n",
    "    step = 0.01\n",
    "\n",
    "    #Initialize Accuracy and threshold\n",
    "    max_acc = 0\n",
    "    best_thresh = -1\n",
    "\n",
    "    #Run through a look increasing threshold by step amount and checking accuracy   \n",
    "    for d in np.arange(dmin, dmax+step, step):\n",
    "\n",
    "        #Test examples for which predicted distance was less than or equal to d (threshold)\n",
    "        #These can be taken as genuine-genuine pairs (for given threshold)\n",
    "        idx1 = predictions.ravel() <= d\n",
    "        \n",
    "        #Test examples for which predicted distance > d (genuine-forged pairs)\n",
    "        idx2 = predictions.ravel() > d\n",
    "       \n",
    "        #How many positive examples are correct\n",
    "        true_positive_rate = float(np.sum(labels[idx1] == 1)) / n_gg_pairs   \n",
    "        true_negative_rate = float(np.sum(labels[idx2] == 0)) / n_gf_pairs\n",
    "        \n",
    "        #Accuracy - avg of above two terms\n",
    "        acc = (true_positive_rate + true_negative_rate)/2       \n",
    "\n",
    "        #If accuracy improved from previous best, make a note of it    \n",
    "        if (acc > max_acc):\n",
    "            max_acc, best_thresh = acc, d\n",
    "           \n",
    "    return max_acc, best_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQSVNodYwaEB"
   },
   "source": [
    "Calculate best threshold and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H61woxSCuxKi"
   },
   "outputs": [],
   "source": [
    "test_acc, threshold = compute_accuracy_thresh(np.array(predictions), np.array(true_labels))\n",
    "print('Test accuracy:', round(test_acc,2))\n",
    "print('Best distance threshold:', round(threshold,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4c__eXSxXNW"
   },
   "source": [
    "#### Visualize Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7KK2FTWHcv7"
   },
   "source": [
    "During Training:\n",
    "\n",
    "1. Load Image\n",
    "2. Resize Image\n",
    "3. Convert it into Numpy array\n",
    "4. Image Augmentation\n",
    "        - Rotate, Scale, shear, flip, add Noise, Translate etc\n",
    "5. (Transfer Learning) - Normalize your image array\n",
    "\n",
    "During Prediction:\n",
    "\n",
    "1. Load Image\n",
    "2. Resize Image\n",
    "3. Convert it into Numpy array\n",
    "4. (Transfer Learning) - Normalize your image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1bRPdtlxaw7"
   },
   "outputs": [],
   "source": [
    "def visualize_prediction(img_pairs, label):\n",
    "\n",
    "    #Load images\n",
    "    first_img = tf.keras.preprocessing.image.load_img(img_pairs[0], target_size=(img_height, img_width))\n",
    "    second_img = tf.keras.preprocessing.image.load_img(img_pairs[1], target_size=(img_height, img_width))\n",
    "    \n",
    "    #Convert to array\n",
    "    first_img_array = tf.keras.preprocessing.image.img_to_array(first_img)\n",
    "    second_img_array = tf.keras.preprocessing.image.img_to_array(second_img)\n",
    "\n",
    "    #Convert to a batch\n",
    "    first_img_array = np.expand_dims(first_img_array, axis=0)\n",
    "    second_img_array = np.expand_dims(second_img_array, axis=0)\n",
    "\n",
    "    #Normalize data\n",
    "    first_img_array_norm = tf.keras.applications.mobilenet.preprocess_input(first_img_array)\n",
    "    second_img_array_norm = tf.keras.applications.mobilenet.preprocess_input(second_img_array)\n",
    "\n",
    "    #Model prediction - distance\n",
    "    distance = model.predict([first_img_array_norm, second_img_array_norm])\n",
    "    print(distance)\n",
    "\n",
    "    print('Actual label:', label)\n",
    "\n",
    "    if distance <= threshold:\n",
    "        print('Predicted label:', 'Same')\n",
    "    else:\n",
    "        print('Predicted label:', 'Different')\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 10))\n",
    "    ax1.imshow(plt.imread(img_pairs[0]), cmap='gray')\n",
    "    ax2.imshow(plt.imread(img_pairs[1]), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHGCy1EEnWF8"
   },
   "outputs": [],
   "source": [
    "#Visualize for genuine-genuine pair\n",
    "idx = np.random.randint(0, len(test_g_g_pairs))\n",
    "visualize_prediction(test_g_g_pairs[idx], 'Same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXWBvimJ0ZmM"
   },
   "outputs": [],
   "source": [
    "#Visualize for genuine-forged pair\n",
    "idx = np.random.randint(0, len(test_g_f_pairs))\n",
    "visualize_prediction(test_g_f_pairs[idx], 'Different')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4xXYjsMUAy7y",
    "X28jYq8NqkmF",
    "_4c__eXSxXNW"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
